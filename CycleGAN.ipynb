{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CycleGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h",
        "colab_type": "text"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28dDUfrc8TAE",
        "colab_type": "text"
      },
      "source": [
        "⭐Before running anything, click 'Runtime' on menu bar, then click 'change runtime type'. Make sure Hardware Accelerator is set to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHsaCLhO44Kl",
        "colab_type": "text"
      },
      "source": [
        "⭐Mounting your google drive👇. Run the block, it will show you link for authorisation. Go to the link location, then allow access, copy the code that pops up, paste it at “Enter your authorization code:”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Khp0eD4vJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aVfE-9Q5gHu",
        "colab_type": "text"
      },
      "source": [
        "⭐Run these three code blocks once. (Click on each block, and then click the ▶ button on the left side of the selected block)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P",
        "colab_type": "text"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images.\n",
        "\n",
        "-   Create a dataset folder under `/dataset` for your dataset.\n",
        "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEWr00PGJns3",
        "colab_type": "text"
      },
      "source": [
        "⭐Run the block below to download your dataset👇. change 'horse2zebra' with the dataset you are training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdOettJxaCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash ./datasets/download_cyclegan_dataset.sh horse2zebra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
        "\n",
        "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
        "\n",
        "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMeq2YLTKxqE",
        "colab_type": "text"
      },
      "source": [
        "⭐ During training, the program will periodically save checkpoints to your google drive in cyclegan/horse2zebra/checkpoints/ folder.\n",
        "Replace horse2zebra in all the paths with the name of the dataset you're training. Run the block below👇 to start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan --checkpoints_dir /gdrive/cyclegan/horse2zebra/checkpoints --n_epochs 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i20YKuSHM-B7",
        "colab_type": "text"
      },
      "source": [
        "⭐You can now close the window. The training will proceed in the cloud. But please check in periodically to ensure that it is still running (You can either go to the link of your notebook, or click runtime->manage sessions, and you will see your active session there). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opa7-9DTOzXC",
        "colab_type": "text"
      },
      "source": [
        "⭐If by chance your session ended/disconnected, You will have to run all the blocks in the 'Install' section (cloning git, mounting google drive etc.), download the dataset from the 'Datasets' section, and then run the block below to continue training👇(remember to replace the horse2zebra with your dataset name):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PobMz-JVIy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan --checkpoints_dir /gdrive/cyclegan/horse2zebra/checkpoints --n_epochs 50 --continue_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdw2itKGXZCs",
        "colab_type": "text"
      },
      "source": [
        "⭐I haven't looked into Testing and Visualizing. They'll need a bit of tweaking. Will fix later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
        "\n",
        "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
        "\n",
        "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN",
        "colab_type": "text"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mgg8raPyizq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G3oVH9DyqLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}